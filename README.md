# **Trash Semantic Segmentation**
![Main](https://user-images.githubusercontent.com/103131249/214734345-8c7eb577-127d-4e3c-8032-c1d03327f77f.png)

## â™» **Contributors**

**CV-16ì¡° ğŸ’¡ ë¹„ì „ê¸¸ì¡ì´ ğŸ’¡**</br>NAVER Connect Foundation boostcamp AI Tech 4th

|ë¯¼ê¸°|ë°•ë¯¼ì§€|ìœ ì˜ì¤€|ì¥ì§€í›ˆ|ìµœë™í˜|
|:----:|:----:|:----:|:---:|:---:|
|[<img alt="revanZX" src="https://avatars.githubusercontent.com/u/25689849?v=4&s=100" width="100">](https://github.com/revanZX)|[<img alt="arislid" src="https://avatars.githubusercontent.com/u/46767966?v=4&s=100" width="100">](https://github.com/arislid)|[<img alt="youngjun04" src="https://avatars.githubusercontent.com/u/113173095?v=4&s=100" width="100">](https://github.com/youngjun04)|[<img alt="FIN443" src="https://avatars.githubusercontent.com/u/70796031?v=4&s=100" width="100">](https://github.com/FIN443)|[<img alt="choipp" src="https://avatars.githubusercontent.com/u/103131249?v=4&s=117" width="100">](https://github.com/choipp)|
|CVAT</br>Stratified K-Fold</br>ConvNeXt| SeMask</br>Pseudo-labeling</br>Ensemble | HorNet Â· Swin</br>Optimization</br>Data version test | ViT-Adapter</br>Data split Â· merge</br>WandB customization| EVA Â· DiNAT</br>Class weights</br>Annotation manual|
|***Data</br>Cleansing***|***Data</br>Cleansing***|***Data</br>Cleansing***|***Data</br>Cleansing***|***Data</br>Cleansing***|
</br>

## â™» **Links**

- [ë¹„ì „ ê¸¸ì¡ì´ Notion ğŸ“](https://vision-pathfinder.notion.site/Segmentation-3149d54760e1403c84ba094d7735a2af)
- [Annotation Tool - CVAT ë§¤ë‰´ì–¼](https://iot-meets-ai.notion.site/CVAT-516e44b823f34280aed3b50d4aaebcab)

## â™» **Result**

![Result](https://user-images.githubusercontent.com/103131249/214524350-2d7bc75b-bb26-41a8-9f82-67841bbc68d9.png)

---

## â™» **ë¬¸ì œ ì •ì˜**
- ëŒ€ëŸ‰ ìƒì‚°, ëŒ€ëŸ‰ ì†Œë¹„ë¡œ ì¸í•œ 'ì“°ë ˆê¸° ëŒ€ë€', 'ë§¤ë¦½ì§€ ë¶€ì¡±'ê³¼ ê°™ì€ ì—¬ëŸ¬ ì‚¬íšŒ ë¬¸ì œ ë°œìƒ
- ì •í™•í•œ ë¶„ë¦¬ìˆ˜ê±°ë¥¼ ë•ëŠ” ìš°ìˆ˜í•œ ì„±ëŠ¥ì˜ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ëª©ì ì˜ í”„ë¡œì íŠ¸

## â™» **Dataset**

![image](https://user-images.githubusercontent.com/113173095/214522741-32cbdcdd-2587-47c5-80c8-52b3c1866d3a.png)

- í•™ìŠµ ë°ì´í„° 3,272ì¥(train 2,617ì¥, validation 655ì¥) / í‰ê°€ ë°ì´í„° 819ì¥
- 11ê°œ í´ë˜ìŠ¤ : Background, General trash, Paper, Paper pack, Metal, Glass, Plastic,
Styrofoam, Plastic bag, Battery, Clothing
- ì´ë¯¸ì§€ í¬ê¸° : (512, 512)

## â™» **Stratified Group K-Fold**

![k-fold](https://user-images.githubusercontent.com/113173095/214523254-3e2f8093-b4e8-4f13-876c-52c7b1289c73.png)

- ë§¤ìš° ë¶ˆê· í˜•í•œ ì „ì²´ train setì˜ í´ë˜ìŠ¤ ë¶„í¬
- ë™ì¼í•œ ë¶„í¬ë¥¼ ê°€ì§€ëŠ” 5ê°œì˜ train, validation set êµ¬ì„±

## â™» **Data Cleansing**

![Annotation Manual](https://user-images.githubusercontent.com/103131249/214528789-16cb5030-34b0-4d59-b65c-ee605fa9ebdd.png)

- ì£¼ì–´ì§„ ë°ì´í„°ì˜ ê²½ê³„ì„  annotation ì˜¤ë¥˜ Â· ë¼ë²¨ë§ ì¼ê´€ì„± ë¶€ì¡± ì´ìŠˆ
- **ì „ì²´ ë°ì´í„° 3272ì¥ ì „ìˆ˜ì¡°ì‚¬ Â· ë©”ë‰´ì–¼ ì‘ì„± ë° Data Cleansing ì§„í–‰**
- **[CVAT](https://github.com/opencv/cvat) annotation tool** ì‚¬ìš© - ìƒë‹¨ Link ë©”ë‰´ì–¼ ì°¸ê³ 
- **Data Versioning**
    - DataV1 : ìˆ˜ì • ì „ ê¸°ë³¸ ë°ì´í„°ì…‹
    - DataV2 : Data Cleansingìœ¼ë¡œ 1ì°¨ ìˆ˜ì •ëœ ë°ì´í„°ì…‹
    - DataV3 : DataV2ë¥¼ classë³„  area ê¸°ì¤€ìœ¼ë¡œ stratified k-fold ì ìš©í•œ ë°ì´í„°ì…‹

## â™» **Model**

![image](https://user-images.githubusercontent.com/103131249/214537394-c87dbf48-7e6a-4886-b7a2-63a65def29ee.png)
| method | UperNet | SeMask | Mask2Former|
|:-:|:-:|:-:|:-:|
|model|Swin</br>Hornet</br>ConvNeXt</br>Beit(V1/V2)|Swin|Swin</br>Vit-adapter (beitV2)|

## â™» **Experiments**

(1) ë‹¨ì¼ ëª¨ë¸ ê²°ê³¼</br>
(2) k-fold ensemble ì ìš© ê²°ê³¼

|      (1) Model       |  mIoU  |      (2) Model       |  mIoU  |
| :------------------: | :----: | :------------------: | :----: |
| upernet_hornet_large | 0.7310 | upernet_hornet_large | 0.7356 |
|        SeMask        | 0.7353 |        SeMask        | 0.7419 |
|   Mask2Former_Swin   | 0.7433 |   Mask2Former_Swin   | 0.7580 |
|     ViT-adapter      | 0.7418 |     ViT-adapter      | 0.7552 |


## â™» **Ensemble**

|Swin-L|Adapter|SeMask|Adapter</br>dataV2|UperNet</br>Beit|Swin-L</br>dataV3|Hornet|Public</br>mIoU|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|âœ”ï¸|âœ”ï¸|âœ”ï¸|||||0.7716|
|âœ”ï¸|âœ”ï¸|âœ”ï¸|âœ”ï¸|âœ”ï¸|âœ”ï¸||0.7810|
|âœ”ï¸|âœ”ï¸|âœ”ï¸|âœ”ï¸|âœ”ï¸|âœ”ï¸|âœ”ï¸|**0.7828**|
- ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì„ ëª¨ë‘ í¬í•¨ì‹œì¼°ì„ ë•Œ ê°€ì¥ ë†’ì€ public mIoU ê¸°ë¡


## â™» **Directory Structure**

```
|-- ğŸ—‚ appendix             : ë°œí‘œìë£Œ ë° WrapUpReport
|-- ğŸ—‚ detection            : MMdet ê¸°ë°˜ Deformable Attention ì˜ì¡´ ì½”ë“œ í¬í•¨
|-- ğŸ—‚ mmsegmentation       : hornet, convnext, Beit í¬í•¨
|-- ğŸ—‚ segmentation         : mask2former_beitV2 adapter í•™ìŠµ
|-- ğŸ—‚ SeMask-Segmentation  : Detectron2 ê¸°ë°˜, mask2former_swin, Semask í•™ìŠµ
|-- ğŸ—‚ tools                : kfold ë° ì•™ìƒë¸” ë“± ìì²´ ì œì‘ íˆ´ í¬í•¨
`-- README.md
```

## â™» **Installation**

### **nvidia-Apex**

```
git clone https://github.com/NVIDIA/apex
cd apex
git checkout 22.05-dev
pip install -v --disable-pip-version-check --no-cache-dir ./
```

### **ViT-Adapter**

```
# Check CUDA & torch version
python -c 'import torch;print(torch.__version__)'
pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html

# Download mmcv-full==1.4.2 >> https://mmcv.readthedocs.io/en/latest/get_started/installation.html#install-with-pip
pip install mmcv-full==1.4.2 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7/index.html
pip install timm==0.4.12
pip install mmdet==2.22.0 # for Mask2Former
pip install mmsegmentation==0.20.2
ln -s ../detection/ops ./

# If error occurred, check below context
cd ops & sh make.sh # compile deformable attention
```

### **Deformable DETR**

```
# Check CUDA version
wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda_11.0.2_450.51.05_linux.run
sh cuda_11.0.2_450.51.05_linux.run

# If cv2 error occurred
apt-get install libgl1-mesa-glx

# Add this code to /root/.bashrc
export PATH="/usr/local/cuda-11.0/bin:$PATH"
export LD_LIBRARY_PATH="/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"

# Check CUDA & nvcc -V
source /root/.bashrc
python -c 'from torch.utils.cpp_extension import CUDA_HOME;print(CUDA_HOME)'

apt-get install g++

# Install MultiScaleDeformableAttention
cd ops
sh make.sh
```

### **Detectron2**

```
apt-get install ninja-build

conda create -n d2 python=3.8
source activate d2
conda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=11.0 -c pytorch
python -m pip install detectron2==0.5 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html

# If error occurred (torch 1.7.0 requires dataclasses, which is not installed)
pip install dataclasses

# MultiScaleDeformableAttention ì„¤ì¹˜ ë°©ë²•ì€ Vit-adapterê³¼ ë™ì¼
git clone https://github.com/IDEA-Research/MaskDINO.git
cd MaskDINO
pip install -r requirements.txt
cd maskdino/modeling/pixel_decoder/ops
sh make.sh
```
